# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12vydERr9s_zUHKSbfUHDCucWjTDmlUVx
"""

import numpy as np
import cv2
from PIL import Image
import IPython.display as display
import matplotlib.pyplot as plt
from IPython.display import display
import numpy as np
from IPython.display import display as ipydisplay


import os
# 图像分割函数
def image_segmentation(image_data, threshold):
    # Convert the image data to a numpy array with float32 data type
    image_data = np.array(image_data, dtype=np.float32)

    # Use threshold segmentation method to set pixel values greater than threshold to 255 and others to 0
    ret, segmented_image = cv2.threshold(image_data, threshold, 255, cv2.THRESH_BINARY)

    return segmented_image

def remove_noise(image_path, kernel_size=(2, 2), iterations=1):
    # 读取图像
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # 图像腐蚀操作
    kernel = np.ones(kernel_size, np.uint8)
    eroded = cv2.erode(img, kernel, iterations=iterations)

    # 图像膨胀操作
    dilated = cv2.dilate(eroded, kernel, iterations=iterations)

    # 阈值化处理
    _, thresholded = cv2.threshold(dilated, 1, 255, cv2.THRESH_BINARY)

    return thresholded

def smooth_fiber_distribution(skeleton_image_path, region_image_path, output_dir):
    # 读取骨架线图像并转换为二进制掩膜
    skeleton_img = cv2.imread(skeleton_image_path, cv2.IMREAD_GRAYSCALE)
    _, skeleton_mask = cv2.threshold(skeleton_img, 1, 255, cv2.THRESH_BINARY)

    # 读取区域图像
    region_img = cv2.imread(region_image_path, cv2.IMREAD_GRAYSCALE)

    # 对骨架掩膜应用形态学膨胀
    kernel = np.ones((3, 3), np.uint8)
    dilated_skeleton_mask = cv2.dilate(skeleton_mask, kernel, iterations=2)

    # 使用膨胀后的骨架掩膜来平滑区域数据
    smoothed_region_img = cv2.bitwise_and(region_img, dilated_skeleton_mask)

    # 显示原始图像和平滑后的图像
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 3, 1)
    plt.imshow(skeleton_img, cmap='gray')
    plt.title('骨架线图像')
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(region_img, cmap='gray')
    plt.title('原始纤维分布区域图像')
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(smoothed_region_img, cmap='gray')
    plt.title('平滑后的纤维分布区域图像')
    plt.axis('off')

    # 保存平滑后的纤维分布区域图像
    output_path = os.path.join(output_dir, 'smoothed_region_image.png')
    cv2.imwrite(output_path, smoothed_region_img)

    plt.show()















if __name__ == "__main__":
    # Define the number of images, n (modify this according to your actual case)
    n = 10

    for i in range(1, n+1):
        # Load grayscale image data
        image_path = f"/content/plot_finished_a_{i}.png"
        image_data = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

        # 设定阈值
        threshold_value = 254

        # 调用图像分割函数，得到分割结果
        segmented_image = image_segmentation(image_data, threshold_value)

        # 显示原始图像和分割后的图像
        plt.figure(figsize=(10, 5))

        plt.subplot(1, 2, 1)
        plt.imshow(image_data, cmap='gray')
        plt.title('Original Image')
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(segmented_image, cmap='gray')
        plt.title('Segmented Image')
        plt.axis('off')

        # 保存分割后的图像
        save_path = f"/content/plot_finished_a_{i}_segmented.png"
        cv2.imwrite(save_path, segmented_image)

        plt.show()

        # 示例用法
        input_image_path = f'/content/plot_finished_a_{i}_segmented.png'
        output_image = remove_noise(input_image_path)

        # 保存输出图像
        output_image_path = f'/content/output_image_{i}.png'
        cv2.imwrite(output_image_path, output_image)

        # 显示输出图像
        output_image = Image.open(output_image_path)
        ipydisplay(output_image)

        # 读取图像
        image_path = f"/content/output_image_{i}.png"
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

        # 二值化图像
        _, thresholded_img = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY)

        # 骨架化
        thinning_img = cv2.ximgproc.thinning(thresholded_img)

        # 保存骨架化图像
        cv2.imwrite(f"/content/skeletonized_image_{i}.png", thinning_img)

        # 绘制中心线在彩色图像上
        color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        contours, _ = cv2.findContours(thinning_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            for j in range(1, len(contour)):
                x1, y1 = contour[j-1][0]
                x2, y2 = contour[j][0]
                cv2.line(color_img, (x1, y1), (x2, y2), (0, 0, 255), 1)  # 将线宽设置为1

        # 保存彩色图像
        cv2.imwrite(f"/content/centerline_image_{i}.png", color_img)

        # 显示结果
        plt.subplot(1, 2, 1)
        plt.imshow(thresholded_img, cmap='gray')
        plt.title(f"Binary Image {i}")
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(color_img)
        plt.title(f"Centerline Image {i}")
        plt.axis('off')

        plt.show()

        # 使用提供的路径进行平滑操作并保存输出图像
        skeleton_image_path = f'/content/skeletonized_image_{i}.png'
        region_image_path = f'/content/plot_finished_a_{i}.png'
        output_dir = '/content/output'  # Replace with the desired output directory

        # 确保输出目录存在
        os.makedirs(output_dir, exist_ok=True)

        smooth_fiber_distribution(skeleton_image_path, region_image_path, output_dir)

import numpy as np
import cv2
from PIL import Image
import IPython.display as display
import matplotlib.pyplot as plt
from IPython.display import display as ipydisplay

import os

def image_segmentation(image_data, threshold):
    if image_data is None or not isinstance(image_data, np.ndarray):
        raise ValueError("Invalid input. image_data must be a valid numpy array.")

    if len(image_data.shape) == 3:
        image_data = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)

    ret, segmented_image = cv2.threshold(image_data, threshold, 255, cv2.THRESH_BINARY)

    return segmented_image

def remove_noise(image_path, kernel_size=(2, 2), iterations=1):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    kernel = np.ones(kernel_size, np.uint8)
    eroded = cv2.erode(img, kernel, iterations=iterations)

    dilated = cv2.dilate(eroded, kernel, iterations=iterations)

    _, thresholded = cv2.threshold(dilated, 1, 255, cv2.THRESH_BINARY)

    return thresholded

def smooth_fiber_distribution(skeleton_image_path, region_image_path, output_dir):
    skeleton_img = cv2.imread(skeleton_image_path, cv2.IMREAD_GRAYSCALE)
    _, skeleton_mask = cv2.threshold(skeleton_img, 1, 255, cv2.THRESH_BINARY)

    region_img = cv2.imread(region_image_path, cv2.IMREAD_GRAYSCALE)

    kernel = np.ones((3, 3), np.uint8)
    dilated_skeleton_mask = cv2.dilate(skeleton_mask, kernel, iterations=2)

    smoothed_region_img = cv2.bitwise_and(region_img, dilated_skeleton_mask)

    plt.figure(figsize=(10, 5))
    plt.subplot(1, 3, 1)
    plt.imshow(skeleton_img, cmap='gray')
    plt.title('骨架线图像')
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(region_img, cmap='gray')
    plt.title('原始纤维分布区域图像')
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(smoothed_region_img, cmap='gray')
    plt.title('平滑后的纤维分布区域图像')
    plt.axis('off')

    output_path = os.path.join(output_dir, 'smoothed_region_image.png')
    cv2.imwrite(output_path, smoothed_region_img)

    plt.show()

if __name__ == "__main__":
    n = 52

    for i in range(1, n+1):
        image_path = f"/content/plot_finished_a_{i}.png"
        image_data = cv2.imread(image_path)

        if image_data is None:
            raise ValueError(f"Unable to load image at path: {image_path}")

        threshold_value = 254

        segmented_image = image_segmentation(image_data, threshold_value)

        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.imshow(image_data, cmap='gray')
        plt.title('Original Image')
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(segmented_image, cmap='gray')
        plt.title('Segmented Image')
        plt.axis('off')

        save_path = f"/content/plot_finished_a_{i}_segmented.png"
        cv2.imwrite(save_path, segmented_image)

        plt.show()

        input_image_path = f'/content/plot_finished_a_{i}_segmented.png'
        output_image = remove_noise(input_image_path)

        output_image_path = f'/content/output_image_{i}.png'
        cv2.imwrite(output_image_path, output_image)

        output_image = Image.open(output_image_path)
        ipydisplay(output_image)

        image_path = f"/content/output_image_{i}.png"
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

        _, thresholded_img = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY)

        thinning_img = cv2.ximgproc.thinning(thresholded_img)

        cv2.imwrite(f"/content/skeletonized_image_{i}.png", thinning_img)

        color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        contours, _ = cv2.findContours(thinning_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            for j in range(1, len(contour)):
                x1, y1 = contour[j-1][0]
                x2, y2 = contour[j][0]
                cv2.line(color_img, (x1, y1), (x2, y2), (0, 0, 255), 1)

        cv2.imwrite(f"/content/centerline_image_{i}.png", color_img)

        plt.subplot(1, 2, 1)
        plt.imshow(thresholded_img, cmap='gray')
        plt.title(f"Binary Image {i}")
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(color_img)
        plt.title(f"Centerline Image {i}")
        plt.axis('off')

        plt.show()

        skeleton_image_path = f'/content/skeletonized_image_{i}.png'
        region_image_path = f'/content/plot_finished_a_{i}.png'
        output_dir = '/content/output'

        os.makedirs(output_dir, exist_ok=True)

        smooth_fiber_distribution(skeleton_image_path, region_image_path, output_dir)

import os
import cv2
import numpy as np

def merge_images(directory):
    # 获取目录中所有`skeletonized_image_n.png`文件的列表
    image_files = [file for file in os.listdir(directory) if file.startswith('skeletonized_image_')]

    if not image_files:
        print("目录中没有找到`skeletonized_image_n.png`文件。")
        return

    # 读取第一张图片以获取其维度
    first_image_path = os.path.join(directory, image_files[0])
    first_image = cv2.imread(first_image_path, cv2.IMREAD_GRAYSCALE)
    merged_image = np.zeros_like(first_image, dtype=np.uint8)

    for image_file in image_files:
        image_path = os.path.join(directory, image_file)
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

        # 在整合图片和当前图片之间找到最大值
        merged_image = np.maximum(merged_image, img)

    return merged_image

if __name__ == "__main__":
    directory = "/content"  # 将此处替换为包含skeletonized images的目录

    merged_image = merge_images(directory)

    # 显示整合后的图片
    plt.imshow(merged_image, cmap='gray')
    plt.title("整合后的图片")
    plt.axis('off')
    plt.show()

    # 保存整合后的图片
    cv2.imwrite("/content/merged_image.png", merged_image)

import cv2
import numpy as np
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt

# 加载灰度图像
image_path = "/content/merged_image.png"
gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# 提取非零像素点的坐标和像素值
non_zero_indices = np.nonzero(gray_image)
y, x = non_zero_indices[0], non_zero_indices[1]
pixel_values = gray_image[y, x]

# 将坐标（x, y）和像素值（pixel_values）合并成一个特征矩阵（X），其中（x, y）是两列坐标
X = np.column_stack((x, y))

# 进行DBSCAN聚类
# Epsilon（eps）和MinPts是DBSCAN的两个关键参数
# 根据你的数据和聚类要求调整它们的值
eps = 2  # 调整此值
min_pts = 2  # 调整此值
dbscan = DBSCAN(eps=eps, min_samples=min_pts)
dbscan_labels = dbscan.fit_predict(X)

# 计算聚类的数量（排除噪声点）
n_clusters = len(np.unique(dbscan_labels)) - 1

# 输出聚类数量
print("聚类数量:", n_clusters)

# 可视化聚类结果
plt.figure(figsize=(12, 6))

# 绘制灰度图像
plt.subplot(1, 2, 1)
plt.imshow(gray_image, cmap='gray')
plt.title("灰度图像")

# 绘制聚类结果，并翻转y轴
plt.subplot(1, 2, 2)
plt.scatter(x, y, c=dbscan_labels, cmap='viridis', marker='o', s=5)
plt.title("DBSCAN聚类结果")
plt.xlabel("X坐标")
plt.ylabel("Y坐标")
plt.gca().invert_yaxis()

plt.show()

import cv2
import numpy as np
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt

# 加载灰度图像
image_path = "/content/merged_image.png"
gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# 提取非零像素点的坐标和像素值
non_zero_indices = np.nonzero(gray_image)
y, x = non_zero_indices[0], non_zero_indices[1]
pixel_values = gray_image[y, x]

# 将坐标（x, y）和像素值（pixel_values）合并成一个特征矩阵（X），其中（x, y）是两列坐标
X = np.column_stack((x, y))

# 进行DBSCAN聚类
# Epsilon（eps）和MinPts是DBSCAN的两个关键参数
# 根据你的数据和聚类要求调整它们的值
eps = 2  # 调整此值
min_pts = 2  # 调整此值
dbscan = DBSCAN(eps=eps, min_samples=min_pts)
dbscan_labels = dbscan.fit_predict(X)

# 计算聚类的数量（排除噪声点）
n_clusters = len(np.unique(dbscan_labels)) - 1

# 输出聚类数量
print("聚类数量:", n_clusters)

# 可视化聚类结果
plt.figure(figsize=(12, 6))

# 绘制灰度图像
plt.subplot(1, 2, 1)
plt.imshow(gray_image, cmap='gray')
plt.title("灰度图像")

# 绘制聚类结果，并翻转y轴
plt.subplot(1, 2, 2)
plt.scatter(x, y, c=dbscan_labels, cmap='viridis', marker='o', s=5)
plt.title("DBSCAN聚类结果")
plt.xlabel("X坐标")
plt.ylabel("Y坐标")
plt.gca().invert_yaxis()

plt.show()











import cv2
import numpy as np
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt

# 加载灰度图像
image_path = "/content/merged_image.png"
gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# 提取非零像素点的坐标和像素值
non_zero_indices = np.nonzero(gray_image)
y, x = non_zero_indices[0], non_zero_indices[1]
pixel_values = gray_image[y, x]

# 将坐标（x, y）和像素值（pixel_values）合并成一个特征矩阵（X），其中（x, y）是两列坐标
X = np.column_stack((x, y))

# 进行DBSCAN聚类
# Epsilon（eps）和MinPts是DBSCAN的两个关键参数
# 根据你的数据和聚类要求调整它们的值
eps = 2  # 调整此值
min_pts = 2  # 调整此值
dbscan = DBSCAN(eps=eps, min_samples=min_pts)
dbscan_labels = dbscan.fit_predict(X)

# 计算聚类的数量（排除噪声点）
n_clusters = len(np.unique(dbscan_labels)) - 1

# 输出聚类数量
print("聚类数量:", n_clusters)

# 可视化聚类结果
plt.figure(figsize=(12, 6))

# 绘制灰度图像
plt.subplot(1, 2, 1)
plt.imshow(gray_image, cmap='gray')
plt.title("灰度图像")

# 绘制聚类结果，并翻转y轴
plt.subplot(1, 2, 2)
plt.scatter(x, y, c=dbscan_labels, cmap='viridis', marker='o', s=5)
plt.title("DBSCAN result")
plt.xlabel("X")
plt.ylabel("Y")
plt.gca().invert_yaxis()

# 保存聚类结果图像
# 创建一个新的图像，根据聚类标签着色
clustered_image = np.zeros_like(gray_image, dtype=np.uint8)

# 将聚类结果映射回原始图像尺寸
for label, (yi, xi) in zip(dbscan_labels, zip(y, x)):
    clustered_image[yi, xi] = label + 1  # Add 1 to avoid setting background as cluster 0

# 保存聚类结果图像
output_image_path = "/content/clustered_image.png"
cv2.imwrite(output_image_path, clustered_image)

plt.show()

import cv2
import numpy as np
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt
import matplotlib.cm as cm

# 加载灰度图像
image_path = "/content/merged_image.png"
gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# 提取非零像素点的坐标和像素值
non_zero_indices = np.nonzero(gray_image)
y, x = non_zero_indices[0], non_zero_indices[1]
pixel_values = gray_image[y, x]

# 将坐标（x, y）和像素值（pixel_values）合并成一个特征矩阵（X），其中（x, y）是两列坐标
X = np.column_stack((x, y))

# 进行DBSCAN聚类
# Epsilon（eps）和MinPts是DBSCAN的两个关键参数
# 根据你的数据和聚类要求调整它们的值
eps = 2  # 调整此值
min_pts = 2  # 调整此值
dbscan = DBSCAN(eps=eps, min_samples=min_pts)
dbscan_labels = dbscan.fit_predict(X)

# 计算聚类的数量（排除噪声点）
n_clusters = len(np.unique(dbscan_labels)) - 1

# 输出聚类数量
print("聚类数量:", n_clusters)

# 可视化聚类结果
plt.figure(figsize=(12, 6))

# 绘制灰度图像
plt.subplot(1, 2, 1)
plt.imshow(gray_image, cmap='gray')
plt.title("灰度图像")

# 绘制聚类结果，并翻转y轴
plt.subplot(1, 2, 2)
plt.scatter(x, y, c=dbscan_labels, cmap='viridis', marker='o', s=5)
plt.title("DBSCAN result")
plt.xlabel("X")
plt.ylabel("Y")
plt.gca().invert_yaxis()

# 保存聚类结果图像
# 创建一个新的彩色图像，根据聚类标签着色
clustered_image = np.zeros((gray_image.shape[0], gray_image.shape[1], 3), dtype=np.uint8)

# 生成不同颜色的colormap
colors = cm.get_cmap('viridis', n_clusters + 1)(range(n_clusters + 1))

# 将聚类结果映射回彩色图像
for label, (yi, xi) in zip(dbscan_labels, zip(y, x)):
    clustered_image[yi, xi] = (colors[label + 1][:3] * 255).astype(np.uint8)  # Add 1 to avoid setting background as cluster 0

# 保存聚类结果彩色图像
output_image_path = "/content/clustered_image.png"
cv2.imwrite(output_image_path, clustered_image)

plt.show()

import cv2
import numpy as np
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt

# 加载灰度图像
image_path = "/content/merged_image.png"
gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# 提取非零像素点的坐标和像素值
non_zero_indices = np.nonzero(gray_image)
y, x = non_zero_indices[0], non_zero_indices[1]
pixel_values = gray_image[y, x]

# 将坐标（x, y）和像素值（pixel_values）合并成一个特征矩阵（X），其中（x, y）是两列坐标
X = np.column_stack((x, y))

# 进行DBSCAN聚类
# Epsilon（eps）和MinPts是DBSCAN的两个关键参数
# 根据你的数据和聚类要求调整它们的值
eps = 2  # 调整此值
min_pts = 2  # 调整此值
dbscan = DBSCAN(eps=eps, min_samples=min_pts)
dbscan_labels = dbscan.fit_predict(X)

# 计算聚类的数量（排除噪声点）
n_clusters = len(np.unique(dbscan_labels)) - 1

# 输出聚类数量
print("聚类数量:", n_clusters)

# 可视化聚类结果
plt.figure(figsize=(12, 6))

# 绘制灰度图像
plt.subplot(1, 2, 1)
plt.imshow(gray_image, cmap='gray')
plt.title("灰度图像")

# 绘制聚类结果，并翻转y轴
plt.subplot(1, 2, 2)
plt.scatter(x, y, c=dbscan_labels, cmap='viridis', marker='o', s=5)
plt.title("DBSCAN聚类结果")
plt.xlabel("X坐标")
plt.ylabel("Y坐标")
plt.gca().invert_yaxis()

plt.show()

# Create a new image to represent the clustering result
clustered_image = np.zeros_like(gray_image)

# Assign cluster labels to corresponding pixels in the new image
for i in range(len(x)):
    clustered_image[y[i], x[i]] = dbscan_labels[i]

# Save the clustered image
output_path = "/content/clustered_image.png"
cv2.imwrite(output_path, clustered_image)

